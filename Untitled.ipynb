{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm \n",
    "from torch.nn import ConstantPad1d\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sorted(glob('audio_22050/*mp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LB(y):  # label方式更改\n",
    "    result = []\n",
    "    start = [0]\n",
    "    for i in range(1,len(y)):\n",
    "        if y[i] != 0:\n",
    "            y[i] = y[i-1] + y[i]\n",
    "        else:\n",
    "            start.append(i)\n",
    "    for c in range(len(start)-1):\n",
    "        tmp = y[start[c]:start[c+1]]\n",
    "        tmp = tmp/np.array(tmp).max()\n",
    "        result.extend(tmp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_size = 1 #sec\n",
    "\n",
    "typs = ['T','N']\n",
    "dic = {k:v for v,k in enumerate(typs)}\n",
    "\n",
    "ii = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed736373977472da70dbfba597d3c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for c in tqdm(range(200)):\n",
    "    \n",
    "    #sound featrue\n",
    "    ID = names[c].split('/')[1][:-4]\n",
    "    waveform_, sample_rate = torchaudio.load(names[c])\n",
    "    \n",
    "    #get labels\n",
    "    f = open('label/'+ID+'.txt')\n",
    "    txts = f.readlines()\n",
    "    c = []\n",
    "    i = 0\n",
    "    for txt in txts:\n",
    "        tmp = txt.split()\n",
    "        typs = dic.get(tmp[2].replace('\\n',''))\n",
    "        start = float(tmp[0])\n",
    "        end = float(tmp[1])\n",
    "        while start <= i < end:\n",
    "            #print(start,end,i,typs)\n",
    "            c.append(typs)\n",
    "            i += shift_size\n",
    "    f.close()\n",
    "    \n",
    "    data[ID] = {}\n",
    "    data[ID]['x'] = waveform_[0]\n",
    "    data[ID]['y'] = torch.tensor(LB(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data,'audio_200.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('audio_mini.pt')\n",
    "IDs = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf_windows(input_,rate=22050,window_size=6,shift_size=1):\n",
    "\n",
    "    pad_len = (window_size/2)*rate\n",
    "    pad = ConstantPad1d(int(pad_len),0)\n",
    "    waveform = pad(input_)\n",
    "\n",
    "    #make a sliding window \n",
    "    x = waveform.unfold(dimension = 0,\n",
    "                             size = window_size*rate,\n",
    "                             step =shift_size*rate).unsqueeze(1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        self.fft = MelSpectrogram() #Fast Fourier Transform featrue = 128   \n",
    "        \n",
    "        cnn = nn.Sequential()\n",
    "        cnn.add_module('conv{0}',   nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0]))\n",
    "        cnn.add_module('norm{0}',   nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        cnn.add_module('relu{0}',   nn.ELU(alpha=1.0))\n",
    "        cnn.add_module('pooling{0}',nn.MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False))\n",
    "        cnn.add_module('drop{0}',   nn.Dropout(p=0.1))\n",
    "                       \n",
    "        cnn.add_module('conv{1}',   nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0]))\n",
    "        cnn.add_module('norm{1}',   nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        cnn.add_module('relu{1}',   nn.ELU(alpha=1.0))\n",
    "        cnn.add_module('pooling{1}',nn.MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False))\n",
    "        cnn.add_module('drop{1}',   nn.Dropout(p=0.1))\n",
    "     \n",
    "        cnn.add_module('conv{2}',   nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0]))        \n",
    "        cnn.add_module('norm{2}',   nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        cnn.add_module('relu{2}',   nn.ELU(alpha=1.0))\n",
    "        cnn.add_module('pooling{2}',nn.MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False))\n",
    "        cnn.add_module('drop{2}',   nn.Dropout(p=0.1))\n",
    "        self.cnn=cnn\n",
    "        \n",
    "        self.LSTM        = nn.LSTM(input_size = 13,hidden_size = 256,num_layers=7,bidirectional=True) #input_size change buy windows size\n",
    "        self.Dropout     = nn.Dropout(p=0.1)\n",
    "        self.BatchNorm1d = nn.BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.Linear      = nn.Linear(in_features=512 , out_features=10, bias=True)\n",
    "        self.Linear2     = nn.Linear(in_features=1280 , out_features=128, bias=True)\n",
    "        self.Linear3     = nn.Linear(in_features=128 , out_features=1, bias=True)  #category number \n",
    "    \n",
    "    def forward(self, x):                      #(seq)\n",
    "        x   = self.fft(x)                      #(batch,1,seq)\n",
    "        x   = self.cnn(x)                      #(batch,chanel,featrue,seq)\n",
    "        x   = x.flatten(start_dim=1,end_dim=2) #(batch,chanel*featrue,seq)\n",
    "        x   = x.transpose(0,1)                 #(seq,batch,chanel*featrue)\n",
    "        x,_ = self.LSTM(x)                     #(seq,batch,64)\n",
    "        x   = self.Dropout(x)                  #(seq,batch,64)\n",
    "        x   = x.transpose(0,1)                 #(batch,seq,64)\n",
    "        x   = x.transpose(1,2)                 #(batch,64,seq)\n",
    "        x   = self.BatchNorm1d(x)              #(batch,64,seq)\n",
    "        x   = x.transpose(1,2)                 #(batch,seq,64)      \n",
    "        x   = self.Linear(x)                   #(batch,seq,10)\n",
    "        x   = x.flatten(start_dim=1)           #(batch,seq*10)\n",
    "        x   = self.Linear2(x)                  #(batch,128)\n",
    "        x   = self.Linear3(x)                  #(batch,10)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "from tqdm.notebook import tqdm \n",
    "from torch import optim\n",
    "from sklearn.metrics import f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c08eb170fb74623adea415a449fd79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-831bf0e6229f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CRNN().double().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "score_trains,score_vals = [],[]\n",
    "best_loss = 10000\n",
    "er = 0\n",
    "epoch = 0\n",
    "h = 4\n",
    "while er <=50 :\n",
    "    epoch += 1\n",
    "    t_loss = 0\n",
    "    batch_nums = 0\n",
    "    for c in tqdm(range(0,len(IDs),h)):\n",
    "        g = 0\n",
    "        xs = torch.LongTensor([])\n",
    "        ys = torch.LongTensor([])\n",
    "        group = np.array([])\n",
    "        for ID in IDs[c:c+h]:\n",
    "\n",
    "            x = sf_windows(data[ID]['x'])\n",
    "            y = data[IDs[0]]['y']\n",
    "\n",
    "            if x.shape[0] > y.shape[0]:\n",
    "                x = x[:y.shape[0]]\n",
    "            if y.shape[0] > x.shape[0]:\n",
    "                y = y[:x.shape[0]]\n",
    "\n",
    "            group = np.append(group,np.repeat(g,y.shape[0]))\n",
    "            g += 1\n",
    "\n",
    "            xs = torch.cat((xs,x))\n",
    "            ys = torch.cat((ys,y))\n",
    "\n",
    "            gss = GroupShuffleSplit(n_splits=2, train_size=.75, random_state=42)\n",
    "\n",
    "        for train_index, test_index in gss.split(xs, ys, group):\n",
    "            X_train, X_test = xs[train_index], xs[test_index]\n",
    "            y_train, y_test = ys[train_index], ys[test_index]\n",
    "\n",
    "            dataloader_X_train = DataLoader(X_train,batch_size=64*3,shuffle=False, num_workers=0,drop_last=True)\n",
    "            dataloader_y_train= DataLoader(y_train,batch_size=64*3,shuffle=False, num_workers=0,drop_last=True)\n",
    "\n",
    "            dataloader_X_test = DataLoader(X_test,batch_size=64*3,shuffle=False, num_workers=0,drop_last=True)\n",
    "            dataloader_y_test= DataLoader(y_test,batch_size=64*3,shuffle=False, num_workers=0,drop_last=True)\n",
    "        \n",
    "        for batch_num,(x,y) in enumerate(zip(dataloader_X_train,dataloader_y_train)):\n",
    "            model.train()\n",
    "            output = model(x.to(device))\n",
    "            loss = loss_fn(output, y.to(device))\n",
    "            if torch.flatten(torch.isnan(loss)).any():\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            loss.float().backward()\n",
    "            optimizer.step()\n",
    "            t_loss += loss\n",
    "            \n",
    "        batch_nums += batch_num\n",
    "    #writer.add_scalar(\"Loss/train\", t_loss/(batch_num, epoch))\n",
    "    score = float(t_loss/batch_nums)\n",
    "    score_trains.append(score)\n",
    "    print('epoch',epoch,'train:',round(score,5),end=' ')\n",
    "\n",
    "    t_loss_v = 0\n",
    "    for x,y in zip(dataloader_X_test,dataloader_y_test):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(x.to(device))\n",
    "        loss = loss_fn(output, y.to(device))\n",
    "\n",
    "    #writer.add_scalar(\"Loss/val\", t_loss_v/batch_num, epoch)\n",
    "    score_val = float(loss)\n",
    "    score_vals.append(score_val)\n",
    "    print('val:',round(score_val,5))\n",
    "\n",
    "    if score_val < best_loss: \n",
    "        best_loss = score_val\n",
    "        torch.save(model.state_dict(), 'model/best_model'+str(epoch)+'.pt')\n",
    "        er = 0\n",
    "    else : \n",
    "        er += 1\n",
    "print('stop at epoch:',epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
